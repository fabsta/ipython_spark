{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Lab setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start docker2boot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Start container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start Spark container\n",
    "docker run -it --name bdu_spark -P bigdatauniversity/spark:latest /etc/bootstrap.sh -bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Start hadoop in container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/etc/bootstrap.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Start Spark shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /opt/ibm/spark-1.3.1_IBM_1-bin-2.6.0\n",
    "./bin/spark-shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext@839755f"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read file\n",
    "val readme = sc.textFile(\"input/tmp/README.md\")\n",
    "# returns a pointer to the RDD\n",
    "#readme: org.apache.spark.rdd.RDD[String] = input/tmp/README.md MapPartitionsRDD[1] at textFile at <console>:21\n",
    "readme.count()\n",
    "#res0: Long = 141\n",
    "readme.first()\n",
    "#res1: String = # Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count lines containing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val linesWithSpark = readme.filter(line => line.contains(\"Spark\"))\n",
    "\n",
    "readme.filter(line => line.contains(\"Spark\")).count()\n",
    "#res2: Long = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Count number of words per line and report the line with most words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find line with most words in it\n",
    "readme.map(line => line.split(\" \").size).reduce((a, b) => if (a > b) a else b)\n",
    "# line 15 contains most words\n",
    "#res3: Int = 15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import java.lang.Math\n",
    "readme.map(line => line.split(\" \").size).reduce((a, b) => Math.max(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Word count on data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val wordCounts = readme.flatMap(line => line.split(\" \")).map(word => (word,\n",
    "1)).reduceByKey((a,b) => a + b)\n",
    "\n",
    "# collect wordCounts\n",
    "\n",
    "wordCounts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Spark caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linesWithSpark.cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
